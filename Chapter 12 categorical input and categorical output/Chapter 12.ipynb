{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to select categorical input features and output is categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # there are some steps to follow for any dataset for the feature selection technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1:- load the datset\n",
    "# step 2:- split the data set into train and test\n",
    "# step 3:- prepare input and prepare output\n",
    "# step 4:- use featue selection technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (191, 9) (191,)\n",
      "test (95, 9) (95,)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# step1:- load the data set\n",
    "dataset=read_csv(r'C:\\Users\\Kumari Sapna\\Desktop\\python notebooks files\\Data Preparation\\Datasets\\breastcancer.csv', header=None)\n",
    "data=dataset.values\n",
    "# split into input and output\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "# covert all into strings\n",
    "x=x.astype(str)\n",
    "\n",
    "# step2:- split the data set \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "print('train', x_train.shape, y_train.shape)\n",
    "print('test', x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (191, 9) (191,)\n",
      "test (95, 9) (95,)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# step1:- load the data set\n",
    "dataset=read_csv(r'C:\\Users\\Kumari Sapna\\Desktop\\python notebooks files\\Data Preparation\\Datasets\\breastcancer.csv', header=None)\n",
    "data=dataset.values\n",
    "# split into input and output\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "# covert all into strings\n",
    "x=x.astype(str)\n",
    "\n",
    "# step2:- split the data set \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "\n",
    "# step 3:- prepare input and prepare output(target)\n",
    " # prepare input first by using ordinal encoder from scikit learn library\n",
    "oe=OrdinalEncoder()\n",
    "oe.fit(x_train)\n",
    "x_train_ip= oe.transform(x_train)\n",
    "x_test_ip= oe.transform(x_test)\n",
    " # prepare output (target) by using label encoder from scikit learn library\n",
    "le=LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_op=le.transform(y_train)\n",
    "y_test_op= le.transform(y_test)\n",
    "\n",
    "print('train', x_train_ip.shape, y_train_op.shape)\n",
    "print('test', x_test_ip.shape, y_test_op.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI- SQUARE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now using the feature selection technique in step 4\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# step1:- load the data set\n",
    "dataset=read_csv(r'C:\\Users\\Kumari Sapna\\Desktop\\python notebooks files\\Data Preparation\\Datasets\\breastcancer.csv', header=None)\n",
    "data=dataset.values\n",
    "# split into input and output\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "# covert all into strings\n",
    "x=x.astype(str)\n",
    "\n",
    "# step2:- split the data set \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "\n",
    "# step 3:- prepare input and prepare output(target)\n",
    " # prepare input first by using ordinal encoder from scikit learn library\n",
    "oe=OrdinalEncoder()\n",
    "oe.fit(x_train)\n",
    "x_train_ip= oe.transform(x_train)\n",
    "x_test_ip= oe.transform(x_test)\n",
    " # prepare output (target) by using label encoder from scikit learn library\n",
    "le=LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_op=le.transform(y_train)\n",
    "y_test_op= le.transform(y_test)\n",
    "\n",
    "# step 4:- using chi-square test\n",
    "fs=SelectKBest(score_func=chi2, k='all')\n",
    "fs.fit(x_train, y_train)\n",
    "x_train_fs =fs.transform(x_train)\n",
    "x_test_fs =fs.transform(x_test)\n",
    " # what are the scores for the features\n",
    "for i in range (len(fs.scores_)):\n",
    "    print(i, fs.scores_[i])\n",
    "\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pylpot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumari Sapna\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\Kumari Sapna\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"'50-59'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e5115c1cab77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# step 4:- using mutual information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmutual_info_classif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mx_train_fs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mx_test_fs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[0mscore_func_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \"\"\"\n\u001b[0;32m    446\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[0m\u001b[0;32m    448\u001b[0m                         copy, random_state)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# Add small noise to continuous features as advised in Kraskov et. al.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0m_astype_copy_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontinuous_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         X[:, continuous_mask] += 1e-10 * means * rng.randn(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: \"'50-59'\""
     ]
    }
   ],
   "source": [
    " # now using the feature selection technique in step 4\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# step1:- load the data set\n",
    "dataset=read_csv(r'C:\\Users\\Kumari Sapna\\Desktop\\python notebooks files\\Data Preparation\\Datasets\\breastcancer.csv', header=None)\n",
    "data=dataset.values\n",
    "# split into input and output\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "# covert all into strings\n",
    "x=x.astype(str)\n",
    "\n",
    "# step2:- split the data set \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "\n",
    "# step 3:- prepare input and prepare output(target)\n",
    " # prepare input first by using ordinal encoder from scikit learn library\n",
    "oe=OrdinalEncoder()\n",
    "oe.fit(x_train)\n",
    "x_train_ip= oe.transform(x_train)\n",
    "x_test_ip= oe.transform(x_test)\n",
    " # prepare output (target) by using label encoder from scikit learn library\n",
    "le=LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_op=le.transform(y_train)\n",
    "y_test_op= le.transform(y_test)\n",
    "\n",
    "# step 4:- using mutual information \n",
    "fs=SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "fs.fit(x_train, y_train)\n",
    "x_train_fs =fs.transform(x_train)\n",
    "x_test_fs=fs.transform(x_test)\n",
    " # what are the scores for the features\n",
    "for i in range (len(fs.scores_)):\n",
    "    print(i, fs.scores_[i])\n",
    "\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.78947368421053\n"
     ]
    }
   ],
   "source": [
    "# first we will use logistic regression for the all the available features to fit the model.\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# step1:- load the data set\n",
    "dataset=read_csv(r'C:\\Users\\Kumari Sapna\\Desktop\\python notebooks files\\Data Preparation\\Datasets\\breastcancer.csv', header=None)\n",
    "data=dataset.values\n",
    "# split into input and output\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "# covert all into strings\n",
    "x=x.astype(str)\n",
    "\n",
    "# step2:- split the data set \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "\n",
    "# step 3:- prepare input and prepare output(target)\n",
    " # prepare input first by using ordinal encoder from scikit learn library\n",
    "oe=OrdinalEncoder()\n",
    "oe.fit(x_train)\n",
    "x_train_ip= oe.transform(x_train)\n",
    "x_test_ip= oe.transform(x_test)\n",
    " # prepare output (target) by using label encoder from scikit learn library\n",
    "le=LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_op=le.transform(y_train)\n",
    "y_test_op= le.transform(y_test)\n",
    "\n",
    "# fit the model \n",
    "model= LogisticRegression(solver='lbfgs')\n",
    "model.fit(x_train_ip, y_train_op)\n",
    "# evaluate the model\n",
    "yhat=model.predict(x_test_ip)\n",
    "# evaluate the predictions\n",
    "accuracy=accuracy_score(y_test_op, yhat)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL BUILT USING CHI SQUARE METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumari Sapna\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\Kumari Sapna\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'numpy.ndarray' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5458051e5853>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# step 4:- using chi-square test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mx_train_fs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mx_test_fs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[0mscore_func_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mchi2\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;31m# numerical stability.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'numpy.ndarray' and 'int'"
     ]
    }
   ],
   "source": [
    "# in this section we wil use chi square features to fit the model to check the accuracy.\n",
    "\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# step1:- load the data set\n",
    "dataset=read_csv(r'C:\\Users\\Kumari Sapna\\Desktop\\python notebooks files\\Data Preparation\\Datasets\\breastcancer.csv', header=None)\n",
    "data=dataset.values\n",
    "# split into input and output\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "# covert all into strings\n",
    "x=x.astype(str)\n",
    "\n",
    "# step2:- split the data set \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "\n",
    "# step 3:- prepare input and prepare output(target)\n",
    " # prepare input first by using ordinal encoder from scikit learn library\n",
    "oe=OrdinalEncoder()\n",
    "oe.fit(x_train)\n",
    "x_train_ip= oe.transform(x_train)\n",
    "x_test_ip= oe.transform(x_test)\n",
    " # prepare output (target) by using label encoder from scikit learn library\n",
    "le=LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_op=le.transform(y_train)\n",
    "y_test_op= le.transform(y_test)\n",
    "\n",
    "# step 4:- using chi-square test\n",
    "fs=SelectKBest(score_func=chi2, k='all')\n",
    "fs.fit(x_train, y_train)\n",
    "x_train_fs =fs.transform(x_train)\n",
    "x_test_fs =fs.transform(x_test)\n",
    "\n",
    "\n",
    "# fit the model \n",
    "model= LogisticRegression(solver='lbfgs')\n",
    "model.fit(x_train_fs, y_train_op)\n",
    "# evaluate the model\n",
    "yhat=model.predict(x_test_fs)\n",
    "# evaluate the predictions\n",
    "accuracy=accuracy_score(y_test_op, yhat)\n",
    "print(accuracy*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Built Using Mutual Information Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumari Sapna\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\Kumari Sapna\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"'50-59'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-e279f52f3a5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# step 4:- using mutual information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmutual_info_classif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mx_train_fs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mx_test_fs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[0mscore_func_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \"\"\"\n\u001b[0;32m    446\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[0m\u001b[0;32m    448\u001b[0m                         copy, random_state)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# Add small noise to continuous features as advised in Kraskov et. al.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0m_astype_copy_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontinuous_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         X[:, continuous_mask] += 1e-10 * means * rng.randn(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: \"'50-59'\""
     ]
    }
   ],
   "source": [
    "# In this section we will use mutual informtion method to to fit the model to check theaccuracy.\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# step1:- load the data set\n",
    "dataset=read_csv(r'C:\\Users\\Kumari Sapna\\Desktop\\python notebooks files\\Data Preparation\\Datasets\\breastcancer.csv', header=None)\n",
    "data=dataset.values\n",
    "# split into input and output\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "# covert all into strings\n",
    "x=x.astype(str)\n",
    "\n",
    "# step2:- split the data set \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "\n",
    "# step 3:- prepare input and prepare output(target)\n",
    " # prepare input first by using ordinal encoder from scikit learn library\n",
    "oe=OrdinalEncoder()\n",
    "oe.fit(x_train)\n",
    "x_train_ip= oe.transform(x_train)\n",
    "x_test_ip= oe.transform(x_test)\n",
    " # prepare output (target) by using label encoder from scikit learn library\n",
    "le=LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_op=le.transform(y_train)\n",
    "y_test_op= le.transform(y_test)\n",
    "\n",
    "# step 4:- using mutual information \n",
    "fs=SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "fs.fit(x_train, y_train)\n",
    "x_train_fs =fs.transform(x_train)\n",
    "x_test_fs=fs.transform(x_test)\n",
    " \n",
    "\n",
    "# fit the model \n",
    "model= LogisticRegression(solver='lbfgs')\n",
    "model.fit(x_train_fs, y_train_op)\n",
    "# evaluate the model\n",
    "yhat=model.predict(x_test_fs)\n",
    "# evaluate the predictions\n",
    "accuracy=accuracy_score(y_test_op, yhat)\n",
    "print(accuracy*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
