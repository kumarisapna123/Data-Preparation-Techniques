{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to select features for numerical input + numerical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (670, 100) (670,)\n",
      "test (330, 100) (330,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# step 1:- load the data set \n",
    "# generate regression dataset\n",
    "x, y=make_regression( n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# step 2:- split into input and output\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "print('train', x_train.shape,y_train.shape)\n",
    "print('test', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.009419262804412633\n",
      "1 1.0188812471305562\n",
      "2 1.2051866307014207\n",
      "3 0.00013830993720419948\n",
      "4 0.16751101484223302\n",
      "5 5.9850827440048295\n",
      "6 0.062405155763893515\n",
      "7 1.455256732598806\n",
      "8 0.4203840175910352\n",
      "9 101.39222471793067\n",
      "10 0.38709117370504115\n",
      "11 1.581124405281074\n",
      "12 3.0144633058998584\n",
      "13 0.2327047368735935\n",
      "14 0.07628130619205689\n",
      "15 4.299651548985038\n",
      "16 1.4975295159807638\n",
      "17 0.2612420506578672\n",
      "18 5.9600054176574915\n",
      "19 0.523218876969846\n",
      "20 0.003365307899643977\n",
      "21 0.024178132506990316\n",
      "22 0.22095778396280447\n",
      "23 0.5767701964214135\n",
      "24 0.6271975911406575\n",
      "25 0.35068705853731175\n",
      "26 0.281877355397396\n",
      "27 0.5842096140411519\n",
      "28 52.19633726736274\n",
      "29 0.04685502877455761\n",
      "30 0.1473232293391444\n",
      "31 0.36848455997040425\n",
      "32 0.07763116157183596\n",
      "33 0.6981398394473672\n",
      "34 45.74404558675307\n",
      "35 2.047375614984328\n",
      "36 0.7862703868467491\n",
      "37 0.99618997694931\n",
      "38 2.7335331193161707\n",
      "39 63.95765560958184\n",
      "40 231.88553989848262\n",
      "41 1.3724475570409402\n",
      "42 0.5818603950314383\n",
      "43 1.072929880177166\n",
      "44 1.066976227907967\n",
      "45 0.3446560117960706\n",
      "46 13.951551067932678\n",
      "47 3.575079742416317\n",
      "48 0.007299045679381343\n",
      "49 0.004650647053144725\n",
      "50 1.0945850321552733\n",
      "51 0.24106451712067403\n",
      "52 0.3551368327380711\n",
      "53 0.020293526056157463\n",
      "54 0.1545674453568483\n",
      "55 2.5925119787983584\n",
      "56 0.3001745620506492\n",
      "57 0.35779795027799605\n",
      "58 3.0600899738851575\n",
      "59 0.8903571662898696\n",
      "60 122.13216383905828\n",
      "61 2.029982220759641\n",
      "62 0.09155072831100695\n",
      "63 1.081122809245369\n",
      "64 0.056040575519853655\n",
      "65 2.9307172637630026\n",
      "66 0.05488609987198577\n",
      "67 1.3327874389448775\n",
      "68 0.14557868750309397\n",
      "69 0.9863306908922869\n",
      "70 0.09266103316038421\n",
      "71 0.08321910835593709\n",
      "72 0.19884688077989923\n",
      "73 2.0657921392028444\n",
      "74 0.23659400576967707\n",
      "75 0.5126077829523027\n",
      "76 1.0956502717037326\n",
      "77 0.015358771643211932\n",
      "78 2.1937304558279007\n",
      "79 1.5745296585103161\n",
      "80 5.360863071852455\n",
      "81 0.04187378847231281\n",
      "82 5.717704617263194\n",
      "83 0.4365596829735328\n",
      "84 5.594437636382666\n",
      "85 6.53822791896016e-05\n",
      "86 0.026748160178718484\n",
      "87 0.4084216346928521\n",
      "88 2.092557026272254\n",
      "89 9.56849762014699\n",
      "90 0.6424450273048271\n",
      "91 0.06579390529607847\n",
      "92 198.70593101795066\n",
      "93 0.07380677254803923\n",
      "94 1.0486054009655172\n",
      "95 0.004106222582962036\n",
      "96 0.04210978474747088\n",
      "97 0.0342282159732776\n",
      "98 0.7924327904077217\n",
      "99 0.015364965777778213\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# in this section we will use pearson's coorelation feature selection method in next step.\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# step 1:- load the data set \n",
    "# generate regression dataset\n",
    "x, y=make_regression( n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# step 2:- split into input and output\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# step 3:- using correaltion test\n",
    "fs=SelectKBest(score_func=f_regression, k='all')\n",
    "fs.fit(x_train, y_train)\n",
    "x_train_fs =fs.transform(x_train)\n",
    "x_test_fs =fs.transform(x_test)\n",
    "\n",
    "# what are the scores for the features\n",
    "for i in range (len(fs.scores_)):\n",
    "    print(i, fs.scores_[i])\n",
    "\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.045484482291907824\n",
      "1 0.0\n",
      "2 0.0\n",
      "3 0.0\n",
      "4 0.024816330308823797\n",
      "5 0.0\n",
      "6 0.0226592483498127\n",
      "7 0.0\n",
      "8 0.0\n",
      "9 0.07432002406270177\n",
      "10 0.0\n",
      "11 0.0\n",
      "12 0.0\n",
      "13 0.0\n",
      "14 0.020390433027765997\n",
      "15 0.004307210952319895\n",
      "16 0.0\n",
      "17 0.0\n",
      "18 0.01656620545853249\n",
      "19 0.0036884128803773564\n",
      "20 0.007579029504275692\n",
      "21 0.018639606838327882\n",
      "22 0.02520605377469698\n",
      "23 0.01796706631129741\n",
      "24 0.06917252453053013\n",
      "25 0.0\n",
      "26 0.02223206448369286\n",
      "27 0.0\n",
      "28 0.007849340866052934\n",
      "29 0.012848688661103225\n",
      "30 0.01740215847662352\n",
      "31 0.008083230830814525\n",
      "32 0.04732065615775882\n",
      "33 0.002829079944537405\n",
      "34 0.028967894063848476\n",
      "35 0.0\n",
      "36 0.07165169905760616\n",
      "37 0.027969169015514606\n",
      "38 0.0\n",
      "39 0.06479570344784369\n",
      "40 0.13769509513592038\n",
      "41 0.008732333573208795\n",
      "42 0.003983482835783203\n",
      "43 0.0\n",
      "44 0.00938732496462924\n",
      "45 0.0\n",
      "46 0.03838510118179039\n",
      "47 0.0\n",
      "48 0.0\n",
      "49 0.0\n",
      "50 0.0\n",
      "51 0.0\n",
      "52 0.0\n",
      "53 0.008130146660047188\n",
      "54 0.041779050134225226\n",
      "55 0.0\n",
      "56 0.0\n",
      "57 0.0\n",
      "58 0.031228272351282893\n",
      "59 0.002689368835120831\n",
      "60 0.14619231754179118\n",
      "61 0.0\n",
      "62 0.0\n",
      "63 0.0\n",
      "64 0.018194152130098118\n",
      "65 0.02136846830418282\n",
      "66 0.046071101437432205\n",
      "67 0.03470732963843304\n",
      "68 0.033530423880775206\n",
      "69 0.0022617161791593787\n",
      "70 0.01833242026957027\n",
      "71 0.0\n",
      "72 0.0\n",
      "73 0.0748760463152296\n",
      "74 0.0\n",
      "75 0.004429306988682491\n",
      "76 0.0026169599594543236\n",
      "77 0.0313541600324454\n",
      "78 0.0\n",
      "79 0.0\n",
      "80 0.0\n",
      "81 0.03393061988659696\n",
      "82 0.010399920696241516\n",
      "83 0.0193728530406716\n",
      "84 0.0\n",
      "85 0.03319087520038311\n",
      "86 0.0\n",
      "87 0.028745427182311545\n",
      "88 0.0\n",
      "89 0.0\n",
      "90 0.0\n",
      "91 0.017697691278957706\n",
      "92 0.12979711825475615\n",
      "93 0.0\n",
      "94 0.0021713283939157613\n",
      "95 0.029994872220527213\n",
      "96 0.0\n",
      "97 0.014427534181586932\n",
      "98 0.0\n",
      "99 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# in this section we will use mutual information feature selection method in next step.\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# step 1:- load the data set \n",
    "# generate regression dataset\n",
    "x, y=make_regression( n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# step 2:- split into input and output\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# step 3:- using mutual information test\n",
    "fs=SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "fs.fit(x_train, y_train)\n",
    "x_train_fs =fs.transform(x_train)\n",
    "x_test_fs =fs.transform(x_test)\n",
    "\n",
    "# what are the scores for the features\n",
    "for i in range (len(fs.scores_)):\n",
    "    print(i, fs.scores_[i])\n",
    "\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model built using all features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08569191074145961\n"
     ]
    }
   ],
   "source": [
    "# in this section we will check the error by using mean absolute error for all the features.\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# step 1:- load the data set \n",
    "# generate regression dataset\n",
    "x, y=make_regression( n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# step 2:- split into input and output\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# fit the model \n",
    "model=LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "# evaluate the model\n",
    "yhat=model.predict(x_test)\n",
    "# evaluate predictions\n",
    "mae=mean_absolute_error(y_test, yhat)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model built using correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 2.739756085615072\n"
     ]
    }
   ],
   "source": [
    "# in this section we will check the error by using mean absolute error  using correlation features..\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# step 1:- load the data set \n",
    "# generate regression dataset\n",
    "x, y=make_regression( n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# step 2:- split into input and output\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# step 3:- using correaltion test\n",
    "fs=SelectKBest(score_func=f_regression, k=10)\n",
    "fs.fit(x_train, y_train)\n",
    "x_train_fs =fs.transform(x_train)\n",
    "x_test_fs =fs.transform(x_test)\n",
    "\n",
    "# fit the model \n",
    "model=LinearRegression()\n",
    "model.fit(x_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat=model.predict(x_test_fs)\n",
    "# evaluate predictions\n",
    "mae=mean_absolute_error(y_test, yhat)\n",
    "print('MAE', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.08499622211656646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# step 1:- load the data set \n",
    "# generate regression dataset\n",
    "x, y=make_regression( n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# step 2:- split into input and output\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# step 3:- using correaltion test\n",
    "fs=SelectKBest(score_func=f_regression, k=88)\n",
    "fs.fit(x_train, y_train)\n",
    "x_train_fs =fs.transform(x_train)\n",
    "x_test_fs =fs.transform(x_test)\n",
    "\n",
    "# fit the model \n",
    "model=LinearRegression()\n",
    "model.fit(x_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat=model.predict(x_test_fs)\n",
    "# evaluate predictions\n",
    "mae=mean_absolute_error(y_test, yhat)\n",
    "print('MAE', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model built using mutual information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.08378300965186727\n"
     ]
    }
   ],
   "source": [
    "# in this section we will check the error by using mean absolute error  using mutual information features..\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# step 1:- load the data set \n",
    "# generate regression dataset\n",
    "x, y=make_regression( n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# step 2:- split into input and output\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# step 3:- using mutual information test\n",
    "fs=SelectKBest(score_func=mutual_info_regression, k=88)\n",
    "fs.fit(x_train, y_train)\n",
    "x_train_fs =fs.transform(x_train)\n",
    "x_test_fs =fs.transform(x_test)\n",
    "\n",
    "# fit the model \n",
    "model=LinearRegression()\n",
    "model.fit(x_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat=model.predict(x_test_fs)\n",
    "# evaluate predictions\n",
    "mae=mean_absolute_error(y_test, yhat)\n",
    "print('MAE', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
